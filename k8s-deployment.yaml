apiVersion: v1
kind: ConfigMap
metadata:
  name: prompt-advisor-config
data:
  HOST: "0.0.0.0"
  PORT: "8000"
  ATPL_SCHEMA_URL: "https://raw.githubusercontent.com/SentriusLLC/atpl/main/atpl.schema.json"
  LLM_ENDPOINT: "https://your-llm-proxy.example.com/v1/chat/completions"
  LLM_MODEL: "gpt-4"
  LLM_ENABLED: "true"
  WEIGHT_PURPOSE: "15"
  WEIGHT_SAFETY: "30"
  WEIGHT_COMPLIANCE: "25"
  WEIGHT_PROVENANCE: "15"
  WEIGHT_AUTONOMY: "15"
---
apiVersion: v1
kind: Secret
metadata:
  name: prompt-advisor-secrets
type: Opaque
stringData:
  LLM_API_KEY: "your-api-key-here"
  # For Keycloak or custom header authentication, use:
  # LLM_CUSTOM_HEADERS: "X-Ztat-Token:your-keycloak-token"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prompt-advisor
  labels:
    app: prompt-advisor
spec:
  replicas: 2
  selector:
    matchLabels:
      app: prompt-advisor
  template:
    metadata:
      labels:
        app: prompt-advisor
    spec:
      containers:
      - name: prompt-advisor
        image: prompt-advisor:latest
        ports:
        - containerPort: 8000
          name: http
        env:
        - name: HOST
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: HOST
        - name: PORT
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: PORT
        - name: ATPL_SCHEMA_URL
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: ATPL_SCHEMA_URL
        - name: LLM_ENDPOINT
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: LLM_ENDPOINT
        - name: LLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: prompt-advisor-secrets
              key: LLM_API_KEY
              optional: true
        - name: LLM_CUSTOM_HEADERS
          valueFrom:
            secretKeyRef:
              name: prompt-advisor-secrets
              key: LLM_CUSTOM_HEADERS
              optional: true
        - name: LLM_MODEL
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: LLM_MODEL
        - name: LLM_ENABLED
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: LLM_ENABLED
        - name: WEIGHT_PURPOSE
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: WEIGHT_PURPOSE
        - name: WEIGHT_SAFETY
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: WEIGHT_SAFETY
        - name: WEIGHT_COMPLIANCE
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: WEIGHT_COMPLIANCE
        - name: WEIGHT_PROVENANCE
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: WEIGHT_PROVENANCE
        - name: WEIGHT_AUTONOMY
          valueFrom:
            configMapKeyRef:
              name: prompt-advisor-config
              key: WEIGHT_AUTONOMY
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: prompt-advisor
  labels:
    app: prompt-advisor
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
    name: http
  selector:
    app: prompt-advisor
